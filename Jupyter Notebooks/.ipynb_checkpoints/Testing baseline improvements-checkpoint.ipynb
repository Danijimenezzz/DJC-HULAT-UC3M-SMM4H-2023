{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7f51a7f",
   "metadata": {},
   "source": [
    "# Multi-class classification of sentiment associated with therapies in English tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb5b510",
   "metadata": {},
   "source": [
    "Daniel Jimenez Campos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf578dd",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "\n",
    "**Training data**: 3009 tweets  \n",
    "**Validation data**: 753 tweets  \n",
    "**Testing data**: TBA  \n",
    "**Evaluation metric**: micro-averaged F1-score  \n",
    "\n",
    "### Data Examples\n",
    "\n",
    "| tweet_id | therapy     | text                                                                                                                                                       | label    |\n",
    "|----------|-------------|------------------------------------------------------------------------------------------------------------------------------------------------------------|----------|\n",
    "| 15309    | meditation  | Did you know meditation can be one of the *most rewarding important things you do in your life*? Did you also know it’s *impossible to not be able to meditate*? For people that believe your mind must somehow go blank you’re wrong unless you’re dead. | positive |\n",
    "| 15262    | acupuncture | abt to get acupuncture for my migraines for the first time ever & i am *terrified*                                                                             | neutral  |\n",
    "\n",
    "### Submission Format\n",
    "\n",
    "Please use the format below for submission. Submissions should contain tweet_id and label separated by tabspace in the same order as below.\n",
    "\n",
    "tweet_id label\n",
    "15309 positive\n",
    "15262 neutral\n",
    "\n",
    "\n",
    "The unzipped submission data needs to be named as *\"answer.txt\"* and be zipped.\n",
    "\n",
    "For more information, please refer to [this link](https://github.com/codalab/codalab-competitions/wiki/User_Building-a-Scoring-Program-for-a-Competition#directory-structure-for-submissions).\n",
    "\n",
    "\n",
    "Simply copy and paste the above Markdown-formatted text into an empty Markdown cell in Jupyter Notebook to display it correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4425ff72",
   "metadata": {},
   "source": [
    "## 1. Importing all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75e22d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package opinion_lexicon to\n",
      "[nltk_data]     C:\\Users\\danij\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     C:\\Users\\danij\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import treebank\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Download the nlkt tools\n",
    "nltk.download('opinion_lexicon')\n",
    "nltk.download('sentiwordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04be53c2",
   "metadata": {},
   "source": [
    "## 2. Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5276bf47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>therapy</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1550591923047600131</td>\n",
       "      <td>cannabis</td>\n",
       "      <td>@chuckschumer YES. Please. Cannabis is legal i...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1496301299691839491</td>\n",
       "      <td>adderall</td>\n",
       "      <td>@youdoingtoomuch I’m a busy girl, adderall kee...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1460587790966657024</td>\n",
       "      <td>adderall</td>\n",
       "      <td>adderall adderall caffeine caffeine caffeine k...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1393586192625528832</td>\n",
       "      <td>alprazolam</td>\n",
       "      <td>@justky1018 See if you can get your doctor to ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1561452418285547520</td>\n",
       "      <td>diazepam</td>\n",
       "      <td>@feytaline Reminds me of the time I had a roug...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id     therapy  \\\n",
       "0  1550591923047600131    cannabis   \n",
       "1  1496301299691839491    adderall   \n",
       "2  1460587790966657024    adderall   \n",
       "3  1393586192625528832  alprazolam   \n",
       "4  1561452418285547520    diazepam   \n",
       "\n",
       "                                                text     label  \n",
       "0  @chuckschumer YES. Please. Cannabis is legal i...   neutral  \n",
       "1  @youdoingtoomuch I’m a busy girl, adderall kee...  positive  \n",
       "2  adderall adderall caffeine caffeine caffeine k...   neutral  \n",
       "3  @justky1018 See if you can get your doctor to ...   neutral  \n",
       "4  @feytaline Reminds me of the time I had a roug...  positive  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"C:\\\\Users\\\\danij\\\\Documents\\\\UC3M\\\\TFG\\\\DATA\\\\train.csv\")\n",
    "dev_data = pd.read_csv(\"C:\\\\Users\\\\danij\\\\Documents\\\\UC3M\\\\TFG\\\\DATA\\\\dev.csv\")\n",
    "\n",
    "# Concatenate the train and dev data\n",
    "data = pd.concat([train_data, dev_data])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa9cd5d",
   "metadata": {},
   "source": [
    "## 3. Cleaning, tokenizing, removing stopwords and lemmatizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57ef928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the stopwords corpus from NLTK (words like \"the\", \"is\", \"and\" that are \n",
    "# commonly used and can be ignored)\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "\n",
    "# Creating a WordNet lemmatizer object from NLTK (used for lemmatizing words to their base form based on context)\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "\n",
    "# Function to clean the text by removing punctuation, converting to lowercase, and stemming words\n",
    "def clean_text(text):\n",
    "    # Removing punctuation characters from the text and converting it to lowercase\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    # Splitting the text into tokens (words) using regular expressions\n",
    "    tokens = re.split('\\W+', text)\n",
    "    # Lemmatizing each word in the tokens list using the WordNet lemmatizer\n",
    "    text = [wn.lemmatize(word) for word in tokens if word not in stopwords]\n",
    "    # Returning the cleaned text\n",
    "    return text\n",
    "\n",
    "\n",
    "## Applying the function to the dataset and convert the 'cleaned_text' column from list to string\n",
    "data['cleaned_text'] = data['text'].apply(lambda x: clean_text(x)).apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5525868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>therapy</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1550591923047600131</td>\n",
       "      <td>cannabis</td>\n",
       "      <td>@chuckschumer YES. Please. Cannabis is legal i...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>chuckschumer yes please cannabis legal license...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1496301299691839491</td>\n",
       "      <td>adderall</td>\n",
       "      <td>@youdoingtoomuch I’m a busy girl, adderall kee...</td>\n",
       "      <td>positive</td>\n",
       "      <td>youdoingtoomuch busy girl adderall keep functi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1460587790966657024</td>\n",
       "      <td>adderall</td>\n",
       "      <td>adderall adderall caffeine caffeine caffeine k...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>adderall adderall caffeine caffeine caffeine k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1393586192625528832</td>\n",
       "      <td>alprazolam</td>\n",
       "      <td>@justky1018 See if you can get your doctor to ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>justky1018 see get doctor prescribe alprazolam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1561452418285547520</td>\n",
       "      <td>diazepam</td>\n",
       "      <td>@feytaline Reminds me of the time I had a roug...</td>\n",
       "      <td>positive</td>\n",
       "      <td>feytaline reminds time rough day took xanax la...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id     therapy  \\\n",
       "0  1550591923047600131    cannabis   \n",
       "1  1496301299691839491    adderall   \n",
       "2  1460587790966657024    adderall   \n",
       "3  1393586192625528832  alprazolam   \n",
       "4  1561452418285547520    diazepam   \n",
       "\n",
       "                                                text     label  \\\n",
       "0  @chuckschumer YES. Please. Cannabis is legal i...   neutral   \n",
       "1  @youdoingtoomuch I’m a busy girl, adderall kee...  positive   \n",
       "2  adderall adderall caffeine caffeine caffeine k...   neutral   \n",
       "3  @justky1018 See if you can get your doctor to ...   neutral   \n",
       "4  @feytaline Reminds me of the time I had a roug...  positive   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  chuckschumer yes please cannabis legal license...  \n",
       "1  youdoingtoomuch busy girl adderall keep functi...  \n",
       "2  adderall adderall caffeine caffeine caffeine k...  \n",
       "3  justky1018 see get doctor prescribe alprazolam...  \n",
       "4  feytaline reminds time rough day took xanax la...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938b83a9",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8205c6",
   "metadata": {},
   "source": [
    "### 4.1 Body length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fdea33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the 'count' function to the 'text' column and storing the result in \n",
    "# a new 'body_len' column\n",
    "data['body_len'] = data['text'].apply(lambda x: len(x) - x.count(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ca5f3a",
   "metadata": {},
   "source": [
    "### 4.2 Count punctuation signs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "617c4a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count the percentage of punctuation characters in a given text\n",
    "def count_punct(text):\n",
    "    # Counting the number of punctuation characters in the text\n",
    "    count = sum([1 for char in text if char in string.punctuation])\n",
    "    # Calculating the percentage of punctuation characters (excluding spaces) in the text\n",
    "    return round(count/(len(text) - text.count(\" \")), 3) * 100\n",
    "\n",
    "\n",
    "# Applying the 'count_punct' function to the 'body_text' column and storing the result in \n",
    "# a new 'punct%' column\n",
    "data['punct%'] = data['text'].apply(lambda x: count_punct(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba82ea1f",
   "metadata": {},
   "source": [
    "### 4.3 Word with associated sentiment weight function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9958c3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>therapy</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1550591923047600131</td>\n",
       "      <td>cannabis</td>\n",
       "      <td>@chuckschumer YES. Please. Cannabis is legal i...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>chuckschumer yes please cannabis legal license...</td>\n",
       "      <td>239</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1496301299691839491</td>\n",
       "      <td>adderall</td>\n",
       "      <td>@youdoingtoomuch I’m a busy girl, adderall kee...</td>\n",
       "      <td>positive</td>\n",
       "      <td>youdoingtoomuch busy girl adderall keep functi...</td>\n",
       "      <td>67</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1460587790966657024</td>\n",
       "      <td>adderall</td>\n",
       "      <td>adderall adderall caffeine caffeine caffeine k...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>adderall adderall caffeine caffeine caffeine k...</td>\n",
       "      <td>166</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1393586192625528832</td>\n",
       "      <td>alprazolam</td>\n",
       "      <td>@justky1018 See if you can get your doctor to ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>justky1018 see get doctor prescribe alprazolam...</td>\n",
       "      <td>129</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1561452418285547520</td>\n",
       "      <td>diazepam</td>\n",
       "      <td>@feytaline Reminds me of the time I had a roug...</td>\n",
       "      <td>positive</td>\n",
       "      <td>feytaline reminds time rough day took xanax la...</td>\n",
       "      <td>236</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id     therapy  \\\n",
       "0  1550591923047600131    cannabis   \n",
       "1  1496301299691839491    adderall   \n",
       "2  1460587790966657024    adderall   \n",
       "3  1393586192625528832  alprazolam   \n",
       "4  1561452418285547520    diazepam   \n",
       "\n",
       "                                                text     label  \\\n",
       "0  @chuckschumer YES. Please. Cannabis is legal i...   neutral   \n",
       "1  @youdoingtoomuch I’m a busy girl, adderall kee...  positive   \n",
       "2  adderall adderall caffeine caffeine caffeine k...   neutral   \n",
       "3  @justky1018 See if you can get your doctor to ...   neutral   \n",
       "4  @feytaline Reminds me of the time I had a roug...  positive   \n",
       "\n",
       "                                        cleaned_text  body_len  punct%  \n",
       "0  chuckschumer yes please cannabis legal license...       239     6.3  \n",
       "1  youdoingtoomuch busy girl adderall keep functi...        67     6.0  \n",
       "2  adderall adderall caffeine caffeine caffeine k...       166     3.6  \n",
       "3  justky1018 see get doctor prescribe alprazolam...       129     2.3  \n",
       "4  feytaline reminds time rough day took xanax la...       236     4.7  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28ad144",
   "metadata": {},
   "source": [
    "Define una función que calcule el sentimiento de cada palabra en un texto, utilizando el léxico de sentimientos apropiado. Aquí tienes un ejemplo utilizando SentiWordNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3932903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_sentiment(word):\n",
    "    synsets = list(swn.senti_synsets(word))\n",
    "    if synsets:\n",
    "        sentiment = synsets[0].pos_score() - synsets[0].neg_score()\n",
    "        return sentiment\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831cf6f1",
   "metadata": {},
   "source": [
    "Itera sobre cada texto en tu dataset y para cada palabra en el texto, utiliza la función get_word_sentiment para obtener el sentimiento de esa palabra. Puedes almacenar los sentimientos en una nueva lista o como una columna adicional en tu dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bca021e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiments'] = data['cleaned_text'].apply(lambda text: np.mean([get_word_sentiment(word) for word in text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e66d2bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>therapy</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1550591923047600131</td>\n",
       "      <td>cannabis</td>\n",
       "      <td>@chuckschumer YES. Please. Cannabis is legal i...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>chuckschumer yes please cannabis legal license...</td>\n",
       "      <td>239</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.027778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1496301299691839491</td>\n",
       "      <td>adderall</td>\n",
       "      <td>@youdoingtoomuch I’m a busy girl, adderall kee...</td>\n",
       "      <td>positive</td>\n",
       "      <td>youdoingtoomuch busy girl adderall keep functi...</td>\n",
       "      <td>67</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.004167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1460587790966657024</td>\n",
       "      <td>adderall</td>\n",
       "      <td>adderall adderall caffeine caffeine caffeine k...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>adderall adderall caffeine caffeine caffeine k...</td>\n",
       "      <td>166</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.033179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1393586192625528832</td>\n",
       "      <td>alprazolam</td>\n",
       "      <td>@justky1018 See if you can get your doctor to ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>justky1018 see get doctor prescribe alprazolam...</td>\n",
       "      <td>129</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.028646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1561452418285547520</td>\n",
       "      <td>diazepam</td>\n",
       "      <td>@feytaline Reminds me of the time I had a roug...</td>\n",
       "      <td>positive</td>\n",
       "      <td>feytaline reminds time rough day took xanax la...</td>\n",
       "      <td>236</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.022727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id     therapy  \\\n",
       "0  1550591923047600131    cannabis   \n",
       "1  1496301299691839491    adderall   \n",
       "2  1460587790966657024    adderall   \n",
       "3  1393586192625528832  alprazolam   \n",
       "4  1561452418285547520    diazepam   \n",
       "\n",
       "                                                text     label  \\\n",
       "0  @chuckschumer YES. Please. Cannabis is legal i...   neutral   \n",
       "1  @youdoingtoomuch I’m a busy girl, adderall kee...  positive   \n",
       "2  adderall adderall caffeine caffeine caffeine k...   neutral   \n",
       "3  @justky1018 See if you can get your doctor to ...   neutral   \n",
       "4  @feytaline Reminds me of the time I had a roug...  positive   \n",
       "\n",
       "                                        cleaned_text  body_len  punct%  \\\n",
       "0  chuckschumer yes please cannabis legal license...       239     6.3   \n",
       "1  youdoingtoomuch busy girl adderall keep functi...        67     6.0   \n",
       "2  adderall adderall caffeine caffeine caffeine k...       166     3.6   \n",
       "3  justky1018 see get doctor prescribe alprazolam...       129     2.3   \n",
       "4  feytaline reminds time rough day took xanax la...       236     4.7   \n",
       "\n",
       "   sentiments  \n",
       "0    0.027778  \n",
       "1    0.004167  \n",
       "2    0.033179  \n",
       "3    0.028646  \n",
       "4    0.022727  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1a099f",
   "metadata": {},
   "source": [
    "### 4.5 Add sentiment intensity to the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2365f5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Sentiment Intensity Analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to get sentiment intensity\n",
    "def get_sentiment_intensity(text):\n",
    "    sentiment = sia.polarity_scores(text)\n",
    "    return sentiment['compound']\n",
    "\n",
    "# Apply the function to the text column\n",
    "data['sentiment_intensity'] = data['cleaned_text'].apply(get_sentiment_intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eaa63e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>therapy</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>sentiments</th>\n",
       "      <th>sentiment_intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1550591923047600131</td>\n",
       "      <td>cannabis</td>\n",
       "      <td>@chuckschumer YES. Please. Cannabis is legal i...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>chuckschumer yes please cannabis legal license...</td>\n",
       "      <td>239</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>-0.2732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1496301299691839491</td>\n",
       "      <td>adderall</td>\n",
       "      <td>@youdoingtoomuch I’m a busy girl, adderall kee...</td>\n",
       "      <td>positive</td>\n",
       "      <td>youdoingtoomuch busy girl adderall keep functi...</td>\n",
       "      <td>67</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.6486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1460587790966657024</td>\n",
       "      <td>adderall</td>\n",
       "      <td>adderall adderall caffeine caffeine caffeine k...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>adderall adderall caffeine caffeine caffeine k...</td>\n",
       "      <td>166</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.033179</td>\n",
       "      <td>-0.8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1393586192625528832</td>\n",
       "      <td>alprazolam</td>\n",
       "      <td>@justky1018 See if you can get your doctor to ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>justky1018 see get doctor prescribe alprazolam...</td>\n",
       "      <td>129</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.028646</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1561452418285547520</td>\n",
       "      <td>diazepam</td>\n",
       "      <td>@feytaline Reminds me of the time I had a roug...</td>\n",
       "      <td>positive</td>\n",
       "      <td>feytaline reminds time rough day took xanax la...</td>\n",
       "      <td>236</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>-0.1119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id     therapy  \\\n",
       "0  1550591923047600131    cannabis   \n",
       "1  1496301299691839491    adderall   \n",
       "2  1460587790966657024    adderall   \n",
       "3  1393586192625528832  alprazolam   \n",
       "4  1561452418285547520    diazepam   \n",
       "\n",
       "                                                text     label  \\\n",
       "0  @chuckschumer YES. Please. Cannabis is legal i...   neutral   \n",
       "1  @youdoingtoomuch I’m a busy girl, adderall kee...  positive   \n",
       "2  adderall adderall caffeine caffeine caffeine k...   neutral   \n",
       "3  @justky1018 See if you can get your doctor to ...   neutral   \n",
       "4  @feytaline Reminds me of the time I had a roug...  positive   \n",
       "\n",
       "                                        cleaned_text  body_len  punct%  \\\n",
       "0  chuckschumer yes please cannabis legal license...       239     6.3   \n",
       "1  youdoingtoomuch busy girl adderall keep functi...        67     6.0   \n",
       "2  adderall adderall caffeine caffeine caffeine k...       166     3.6   \n",
       "3  justky1018 see get doctor prescribe alprazolam...       129     2.3   \n",
       "4  feytaline reminds time rough day took xanax la...       236     4.7   \n",
       "\n",
       "   sentiments  sentiment_intensity  \n",
       "0    0.027778              -0.2732  \n",
       "1    0.004167               0.6486  \n",
       "2    0.033179              -0.8062  \n",
       "3    0.028646               0.0000  \n",
       "4    0.022727              -0.1119  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bb9477",
   "metadata": {},
   "source": [
    "### Split into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd84c853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "# The 'body_text', 'body_len', and 'punct%' columns are used as the features (X)\n",
    "# The 'label' column is used as the target variable (y)\n",
    "# The test_size parameter is set to 0.2, which means 20% of the data will be used for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[['cleaned_text', 'body_len', 'punct%', 'sentiments', 'sentiment_intensity']], data['label'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9f9d915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>therapy</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>sentiments</th>\n",
       "      <th>sentiment_intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1550591923047600131</td>\n",
       "      <td>cannabis</td>\n",
       "      <td>@chuckschumer YES. Please. Cannabis is legal i...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>chuckschumer yes please cannabis legal license...</td>\n",
       "      <td>239</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>-0.2732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1496301299691839491</td>\n",
       "      <td>adderall</td>\n",
       "      <td>@youdoingtoomuch I’m a busy girl, adderall kee...</td>\n",
       "      <td>positive</td>\n",
       "      <td>youdoingtoomuch busy girl adderall keep functi...</td>\n",
       "      <td>67</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.6486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1460587790966657024</td>\n",
       "      <td>adderall</td>\n",
       "      <td>adderall adderall caffeine caffeine caffeine k...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>adderall adderall caffeine caffeine caffeine k...</td>\n",
       "      <td>166</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.033179</td>\n",
       "      <td>-0.8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1393586192625528832</td>\n",
       "      <td>alprazolam</td>\n",
       "      <td>@justky1018 See if you can get your doctor to ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>justky1018 see get doctor prescribe alprazolam...</td>\n",
       "      <td>129</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.028646</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1561452418285547520</td>\n",
       "      <td>diazepam</td>\n",
       "      <td>@feytaline Reminds me of the time I had a roug...</td>\n",
       "      <td>positive</td>\n",
       "      <td>feytaline reminds time rough day took xanax la...</td>\n",
       "      <td>236</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>-0.1119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id     therapy  \\\n",
       "0  1550591923047600131    cannabis   \n",
       "1  1496301299691839491    adderall   \n",
       "2  1460587790966657024    adderall   \n",
       "3  1393586192625528832  alprazolam   \n",
       "4  1561452418285547520    diazepam   \n",
       "\n",
       "                                                text     label  \\\n",
       "0  @chuckschumer YES. Please. Cannabis is legal i...   neutral   \n",
       "1  @youdoingtoomuch I’m a busy girl, adderall kee...  positive   \n",
       "2  adderall adderall caffeine caffeine caffeine k...   neutral   \n",
       "3  @justky1018 See if you can get your doctor to ...   neutral   \n",
       "4  @feytaline Reminds me of the time I had a roug...  positive   \n",
       "\n",
       "                                        cleaned_text  body_len  punct%  \\\n",
       "0  chuckschumer yes please cannabis legal license...       239     6.3   \n",
       "1  youdoingtoomuch busy girl adderall keep functi...        67     6.0   \n",
       "2  adderall adderall caffeine caffeine caffeine k...       166     3.6   \n",
       "3  justky1018 see get doctor prescribe alprazolam...       129     2.3   \n",
       "4  feytaline reminds time rough day took xanax la...       236     4.7   \n",
       "\n",
       "   sentiments  sentiment_intensity  \n",
       "0    0.027778              -0.2732  \n",
       "1    0.004167               0.6486  \n",
       "2    0.033179              -0.8062  \n",
       "3    0.028646               0.0000  \n",
       "4    0.022727              -0.1119  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show data before vectorizing\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f6c0bb",
   "metadata": {},
   "source": [
    "### Vectorize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9972467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>sentiments</th>\n",
       "      <th>sentiment_intensity</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>9848</th>\n",
       "      <th>9849</th>\n",
       "      <th>9850</th>\n",
       "      <th>9851</th>\n",
       "      <th>9852</th>\n",
       "      <th>9853</th>\n",
       "      <th>9854</th>\n",
       "      <th>9855</th>\n",
       "      <th>9856</th>\n",
       "      <th>9857</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>209</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.041139</td>\n",
       "      <td>0.5478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>198</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.026012</td>\n",
       "      <td>-0.8942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>223</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.031457</td>\n",
       "      <td>0.8806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>273</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.029279</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>-0.5664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9862 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_len  punct%  sentiments  sentiment_intensity    0    1    2    3    4  \\\n",
       "0       209     2.9    0.041139               0.5478  0.0  0.0  0.0  0.0  0.0   \n",
       "1       198     5.1    0.026012              -0.8942  0.0  0.0  0.0  0.0  0.0   \n",
       "2       223     2.2    0.031457               0.8806  0.0  0.0  0.0  0.0  0.0   \n",
       "3       273     2.9    0.029279               0.4404  0.0  0.0  0.0  0.0  0.0   \n",
       "4       136     0.7    0.039062              -0.5664  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "     5  ...  9848  9849  9850  9851  9852  9853  9854  9855  9856  9857  \n",
       "0  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 9862 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a TfidfVectorizer object with the analyzer parameter set to the clean_text function\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "\n",
    "# Fitting the TfidfVectorizer on the 'text' column of the training set\n",
    "tfidf_vect_fit = tfidf_vect.fit(X_train['cleaned_text'])\n",
    "\n",
    "# Transforming the 'text' column of the training and testing sets into TF-IDF features\n",
    "tfidf_train = tfidf_vect_fit.transform(X_train['cleaned_text'])\n",
    "tfidf_test = tfidf_vect_fit.transform(X_test['cleaned_text'])\n",
    "\n",
    "# Concatenating the 'body_len' and 'punct%' and 'sentiments' columns with the TF-IDF features of the training set\n",
    "X_train_vect = pd.concat([X_train[['body_len', 'punct%', 'sentiments', 'sentiment_intensity']].reset_index(drop=True), \n",
    "                          pd.DataFrame(tfidf_train.toarray())], axis=1)\n",
    "\n",
    "# Concatenating the 'body_len' and 'punct%'  and 'sentiments'columns with the TF-IDF features of the testing set\n",
    "X_test_vect = pd.concat([X_test[['body_len', 'punct%', 'sentiments', 'sentiment_intensity']].reset_index(drop=True), \n",
    "                         pd.DataFrame(tfidf_test.toarray())], axis=1)\n",
    "\n",
    "# Displaying the head (first few rows) of the X_train_vect DataFrame\n",
    "X_train_vect.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c328dbb5",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b67cefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to show hyperparameters values\n",
    "def print_results(results):\n",
    "    print('BEST PARAMS: {}\\n'.format(results.best_params_))\n",
    "\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876ac8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [5, 50, 250],\n",
    "    'max_depth': [2, 4, 8, 16, 32, None]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(rf, parameters, cv=5)\n",
    "cv.fit(tr_features, tr_labels.values.ravel())\n",
    "\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef84764",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bb35c7",
   "metadata": {},
   "source": [
    "### Write out pickled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7c1f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(cv.best_estimator_, 'C:\\\\Users\\\\danij\\\\Documents\\\\LEARNING\\\\DATASETS\\\\ML_Algorithms_data\\\\RF_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d015785",
   "metadata": {},
   "source": [
    "### Final evaluation of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cae1ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f836e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the RandomForestClassifier from the sklearn.ensemble module\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "# Creating a RandomForestClassifier object with specified parameters\n",
    "rf = RandomForestClassifier(n_estimators=150, max_depth=None, n_jobs=-1)\n",
    "\n",
    "# Measuring the time taken to fit (train) the RandomForestClassifier on the training data\n",
    "start = time.time()\n",
    "rf_model = rf.fit(X_train_vect, y_train)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "# Measuring the time taken to make predictions using the trained RandomForestClassifier \n",
    "# on the testing data\n",
    "start = time.time()\n",
    "y_pred = rf_model.predict(X_test_vect)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "# Computing precision, recall, fscore, and support values for the predicted results\n",
    "precision, recall, fscore, support = score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Printing the precision, recall, and F1-score\n",
    "print('Macro Average Precision:', precision)\n",
    "print('Macro Average Recall:', recall)\n",
    "print('Macro Average F1-score:', fscore)\n",
    "print('Support:', support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d396de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the GradientBoostingClassifier from the sklearn.ensemble module\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import time\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "# Creating a GradientBoostingClassifier object with specified parameters\n",
    "gb = GradientBoostingClassifier(n_estimators=150, max_depth=11)\n",
    "\n",
    "# Measuring the time taken to fit (train) the GradientBoostingClassifier on the training data\n",
    "start = time.time()\n",
    "gb_model = gb.fit(X_train_vect, y_train)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "# Measuring the time taken to make predictions using the trained GradientBoostingClassifier on \n",
    "# the testing data\n",
    "start = time.time()\n",
    "y_pred = gb_model.predict(X_test_vect)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "# Computing precision, recall, fscore, and support values for the predicted results\n",
    "precision, recall, fscore, support = score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Printing the precision, recall, and F1-score\n",
    "print('Macro Average Precision:', precision)\n",
    "print('Macro Average Recall:', recall)\n",
    "print('Macro Average F1-score:', fscore)\n",
    "print('Support:', support)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
