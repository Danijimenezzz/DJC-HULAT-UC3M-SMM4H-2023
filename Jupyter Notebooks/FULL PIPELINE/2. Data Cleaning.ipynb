{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7e0957b",
   "metadata": {},
   "source": [
    "## Data Cleaning: Cleaning, tokenizing, removing stopwords and lemmatizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5b6ac76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package opinion_lexicon to\n",
      "[nltk_data]     C:\\Users\\danij\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     C:\\Users\\danij\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import treebank\n",
    "\n",
    "# Download the nlkt tools\n",
    "nltk.download('opinion_lexicon')\n",
    "nltk.download('sentiwordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d141d7b",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd999832",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danij\\AppData\\Local\\Temp\\ipykernel_2596\\608871259.py:16: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>therapy</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1454224517895688192</td>\n",
       "      <td>adderall</td>\n",
       "      <td>wait until i get an adderall prescription.  imma be on time for Everything</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1426258820376842243</td>\n",
       "      <td>oxycodone</td>\n",
       "      <td>@Sassychickie @kelly_rdc Fentanyl, OxyContin and Oxycodone! I‚Äôve had 2 back surgeries. Never again!!!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1473007602170798082</td>\n",
       "      <td>cbd</td>\n",
       "      <td>a fun juggling act of mine is taking adderall and drinking coffee, then needing CBD in the afternoon to soothe my anxiety</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1561156143405502466</td>\n",
       "      <td>percocet</td>\n",
       "      <td>percocet roxycodone with some xanax that i had crushed up in some dust\\nelevated to another dimension so i got a limp in my strut</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1559923718578741248</td>\n",
       "      <td>adderall</td>\n",
       "      <td>first day of adderall and i feel üòµ‚Äçüí´üòµ‚Äçüí´üòµ‚Äçüí´üòµ‚Äçüí´</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id    therapy  \\\n",
       "0  1454224517895688192  adderall    \n",
       "1  1426258820376842243  oxycodone   \n",
       "2  1473007602170798082  cbd         \n",
       "3  1561156143405502466  percocet    \n",
       "4  1559923718578741248  adderall    \n",
       "\n",
       "                                                                                                                                text  \\\n",
       "0  wait until i get an adderall prescription.  imma be on time for Everything                                                          \n",
       "1  @Sassychickie @kelly_rdc Fentanyl, OxyContin and Oxycodone! I‚Äôve had 2 back surgeries. Never again!!!                               \n",
       "2  a fun juggling act of mine is taking adderall and drinking coffee, then needing CBD in the afternoon to soothe my anxiety           \n",
       "3  percocet roxycodone with some xanax that i had crushed up in some dust\\nelevated to another dimension so i got a limp in my strut   \n",
       "4  first day of adderall and i feel üòµ‚Äçüí´üòµ‚Äçüí´üòµ‚Äçüí´üòµ‚Äçüí´                                                                                       \n",
       "\n",
       "      label  \n",
       "0  neutral   \n",
       "1  negative  \n",
       "2  neutral   \n",
       "3  neutral   \n",
       "4  negative  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"C:\\\\Users\\\\danij\\\\Documents\\\\UC3M\\\\TFG\\\\DATA\\\\train.csv\")\n",
    "dev_data = pd.read_csv(\"C:\\\\Users\\\\danij\\\\Documents\\\\UC3M\\\\TFG\\\\DATA\\\\dev.csv\")\n",
    "\n",
    "# Concatenate the train and dev data\n",
    "# data = pd.concat([train_data, dev_data])\n",
    "data = train_data\n",
    "\n",
    "# Test data\n",
    "# test_data = pd.read_csv(\"C:\\\\Users\\\\danij\\\\Documents\\\\UC3M\\\\TFG\\\\DATA\\\\test.csv\")\n",
    "test_data = dev_data\n",
    "\n",
    "# Set the display options to show the full content of each row\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85bdc763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3009\n",
      "753\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cb75094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the stopwords corpus from NLTK \n",
    "# words like \"the\", \"is\", \"and\" that are commonly used and can be ignored\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# Creating a WordNet lemmatizer object from NLTK (used for lemmatizing words to their base form based on context)\n",
    "wn = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43d31d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean the text by removing punctuation, converting to lowercase, and lemmatizing words\n",
    "def clean_text(text):\n",
    "    # Removing punctuation characters from the text and converting it to lowercase\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    # Splitting the text into tokens (words) using regular expressions that match just words\n",
    "    tokens = re.split('\\W+', text)\n",
    "    # Lemmatizing each word in the tokens list using the WordNet lemmatizer\n",
    "    text = [wn.lemmatize(word) for word in tokens if word not in stopwords]\n",
    "    # Returning the cleaned text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "438478d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>therapy</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1454224517895688192</td>\n",
       "      <td>adderall</td>\n",
       "      <td>wait until i get an adderall prescription.  imma be on time for Everything</td>\n",
       "      <td>neutral</td>\n",
       "      <td>wait get adderall prescription imma time everything</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1426258820376842243</td>\n",
       "      <td>oxycodone</td>\n",
       "      <td>@Sassychickie @kelly_rdc Fentanyl, OxyContin and Oxycodone! I‚Äôve had 2 back surgeries. Never again!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>sassychickie kellyrdc fentanyl oxycontin oxycodone 2 back surgery never</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1473007602170798082</td>\n",
       "      <td>cbd</td>\n",
       "      <td>a fun juggling act of mine is taking adderall and drinking coffee, then needing CBD in the afternoon to soothe my anxiety</td>\n",
       "      <td>neutral</td>\n",
       "      <td>fun juggling act mine taking adderall drinking coffee needing cbd afternoon soothe anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1561156143405502466</td>\n",
       "      <td>percocet</td>\n",
       "      <td>percocet roxycodone with some xanax that i had crushed up in some dust\\nelevated to another dimension so i got a limp in my strut</td>\n",
       "      <td>neutral</td>\n",
       "      <td>percocet roxycodone xanax crushed dust elevated another dimension got limp strut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1559923718578741248</td>\n",
       "      <td>adderall</td>\n",
       "      <td>first day of adderall and i feel üòµ‚Äçüí´üòµ‚Äçüí´üòµ‚Äçüí´üòµ‚Äçüí´</td>\n",
       "      <td>negative</td>\n",
       "      <td>first day adderall feel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id    therapy  \\\n",
       "0  1454224517895688192  adderall    \n",
       "1  1426258820376842243  oxycodone   \n",
       "2  1473007602170798082  cbd         \n",
       "3  1561156143405502466  percocet    \n",
       "4  1559923718578741248  adderall    \n",
       "\n",
       "                                                                                                                                text  \\\n",
       "0  wait until i get an adderall prescription.  imma be on time for Everything                                                          \n",
       "1  @Sassychickie @kelly_rdc Fentanyl, OxyContin and Oxycodone! I‚Äôve had 2 back surgeries. Never again!!!                               \n",
       "2  a fun juggling act of mine is taking adderall and drinking coffee, then needing CBD in the afternoon to soothe my anxiety           \n",
       "3  percocet roxycodone with some xanax that i had crushed up in some dust\\nelevated to another dimension so i got a limp in my strut   \n",
       "4  first day of adderall and i feel üòµ‚Äçüí´üòµ‚Äçüí´üòµ‚Äçüí´üòµ‚Äçüí´                                                                                       \n",
       "\n",
       "      label  \\\n",
       "0  neutral    \n",
       "1  negative   \n",
       "2  neutral    \n",
       "3  neutral    \n",
       "4  negative   \n",
       "\n",
       "                                                                                 cleaned_text  \n",
       "0  wait get adderall prescription imma time everything                                         \n",
       "1  sassychickie kellyrdc fentanyl oxycontin oxycodone 2 back surgery never                     \n",
       "2  fun juggling act mine taking adderall drinking coffee needing cbd afternoon soothe anxiety  \n",
       "3  percocet roxycodone xanax crushed dust elevated another dimension got limp strut            \n",
       "4  first day adderall feel                                                                     "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Applying the function to the train dataset and convert the 'cleaned_text' column from list to string\n",
    "data['cleaned_text'] = data['text'].apply(lambda x: clean_text(x)).apply(' '.join)\n",
    "\n",
    "## Applying the function to the test dataset and convert the 'cleaned_text' column from list to string\n",
    "test_data['cleaned_text'] = test_data['text'].apply(lambda x: clean_text(x)).apply(' '.join)\n",
    "\n",
    "# Show the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1b639d",
   "metadata": {},
   "source": [
    "### Save cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a827b81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"C:\\\\Users\\\\danij\\\\Documents\\\\UC3M\\\\TFG\\\\DATA\\\\cleaned_text.csv\", mode='w',index=False)\n",
    "\n",
    "test_data.to_csv(\"C:\\\\Users\\\\danij\\\\Documents\\\\UC3M\\\\TFG\\\\DATA\\\\test_cleaned_text.csv\", mode='w',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
