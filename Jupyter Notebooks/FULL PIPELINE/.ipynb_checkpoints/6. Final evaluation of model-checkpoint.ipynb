{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ee142c6",
   "metadata": {},
   "source": [
    "### Final evaluation of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c5b3f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import time\n",
    "\n",
    "import joblib\n",
    "import lazypredict\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from lazypredict.Supervised import LazyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "406c6f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect = pd.read_csv(\"C:\\\\Users\\\\danij\\\\Documents\\\\UC3M\\\\TFG\\\\DATA\\\\X_train_vect.csv\")\n",
    "X_test_vect = pd.read_csv(\"C:\\\\Users\\\\danij\\\\Documents\\\\UC3M\\\\TFG\\\\DATA\\\\X_test_vect.csv\")\n",
    "\n",
    "y_train = pd.read_csv(\"C:\\\\Users\\\\danij\\\\Documents\\\\UC3M\\\\TFG\\\\DATA\\\\train_labels.csv\")\n",
    "y_test = pd.read_csv(\"C:\\\\Users\\\\danij\\\\Documents\\\\UC3M\\\\TFG\\\\DATA\\\\test_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee1d276e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3009\n",
      "753\n",
      "3009\n",
      "753\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_vect))\n",
    "print(len(X_test_vect))\n",
    "\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ca3afa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a RandomForestClassifier object with specified parameters\n",
    "rf = RandomForestClassifier(n_estimators=150, max_depth=None, n_jobs=-1)\n",
    "\n",
    "# Measuring the time taken to fit (train) the RandomForestClassifier on the training data\n",
    "start = time.time()\n",
    "\n",
    "# Training the model\n",
    "rf_model = rf.fit(X_train_vect, y_train)\n",
    "# Save the model for future use\n",
    "joblib.dump(rf_model, \"C:\\\\Users\\\\danij\\\\Documents\\\\UC3M\\\\TFG\\\\MODELS\\\\rf_model.pkl\")\n",
    "\n",
    "# Calculating total time taken to train the model\n",
    "end = time.time()\n",
    "fit_time = (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35c0a77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring the time taken to make predictions on the testing data\n",
    "start = time.time()\n",
    "\n",
    "# Making predictions\n",
    "test_predictions = rf_model.predict(X_test_vect)\n",
    "\n",
    "# Calculating total time taken to train the model\n",
    "end = time.time()\n",
    "pred_time = (end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70136dba",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2912fb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Average Precision: 0.6375120004042242\n",
      "Macro Average Recall: 0.3628971332993484\n",
      "Macro Average F1-score: 0.33032155416951836\n",
      "Fit time: 5.539725303649902\n",
      "Predict time: 0.3283960819244385\n"
     ]
    }
   ],
   "source": [
    "# Computing precision, recall, fscore, and support values for the predicted results\n",
    "precision, recall, fscore, support = score(y_test, test_predictions, average='macro')\n",
    "\n",
    "# Printing the precision, recall, and F1-score\n",
    "print('Macro Average Precision:', precision)\n",
    "print('Macro Average Recall:', recall)\n",
    "print('Macro Average F1-score:', fscore)\n",
    "print('Fit time:', fit_time)\n",
    "print('Predict time:', pred_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9595a6ed",
   "metadata": {},
   "source": [
    "### Evaluating other possible models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d447ed63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████████████████████████████████████████████▏  | 28/29 [32:28<00:39, 39.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12696\n",
      "[LightGBM] [Info] Number of data points in the train set: 3009, number of used features: 440\n",
      "[LightGBM] [Info] Start training from score -2.244172\n",
      "[LightGBM] [Info] Start training from score -0.350192\n",
      "[LightGBM] [Info] Start training from score -1.663727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [32:35<00:00, 67.44s/it]\n"
     ]
    }
   ],
   "source": [
    "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "models, predictions = clf.fit(X_train_vect, X_test_vect, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75efd43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Accuracy  Balanced Accuracy ROC AUC  F1 Score  \\\n",
      "Model                                                                          \n",
      "PassiveAggressiveClassifier        0.61               0.45    None      0.61   \n",
      "AdaBoostClassifier                 0.68               0.44    None      0.64   \n",
      "Perceptron                         0.62               0.44    None      0.61   \n",
      "LinearSVC                          0.59               0.44    None      0.59   \n",
      "LGBMClassifier                     0.68               0.43    None      0.64   \n",
      "DecisionTreeClassifier             0.62               0.43    None      0.61   \n",
      "RidgeClassifier                    0.62               0.43    None      0.61   \n",
      "LogisticRegression                 0.66               0.42    None      0.62   \n",
      "RidgeClassifierCV                  0.62               0.41    None      0.60   \n",
      "NearestCentroid                    0.68               0.41    None      0.62   \n",
      "ExtraTreeClassifier                0.59               0.39    None      0.58   \n",
      "GaussianNB                         0.56               0.38    None      0.56   \n",
      "BaggingClassifier                  0.67               0.38    None      0.60   \n",
      "RandomForestClassifier             0.69               0.36    None      0.58   \n",
      "ExtraTreesClassifier               0.69               0.36    None      0.58   \n",
      "BernoulliNB                        0.69               0.35    None      0.57   \n",
      "LinearDiscriminantAnalysis         0.27               0.35    None      0.29   \n",
      "SGDClassifier                      0.69               0.35    None      0.57   \n",
      "SVC                                0.68               0.34    None      0.56   \n",
      "KNeighborsClassifier               0.68               0.34    None      0.55   \n",
      "QuadraticDiscriminantAnalysis      0.47               0.34    None      0.48   \n",
      "LabelSpreading                     0.13               0.34    None      0.04   \n",
      "LabelPropagation                   0.13               0.34    None      0.04   \n",
      "CalibratedClassifierCV             0.68               0.33    None      0.55   \n",
      "DummyClassifier                    0.68               0.33    None      0.55   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "PassiveAggressiveClassifier         10.77  \n",
      "AdaBoostClassifier                  29.94  \n",
      "Perceptron                           5.64  \n",
      "LinearSVC                          310.65  \n",
      "LGBMClassifier                       7.16  \n",
      "DecisionTreeClassifier              16.66  \n",
      "RidgeClassifier                      6.17  \n",
      "LogisticRegression                  11.39  \n",
      "RidgeClassifierCV                   59.36  \n",
      "NearestCentroid                      2.82  \n",
      "ExtraTreeClassifier                  3.57  \n",
      "GaussianNB                           4.94  \n",
      "BaggingClassifier                   61.30  \n",
      "RandomForestClassifier              11.69  \n",
      "ExtraTreesClassifier                27.25  \n",
      "BernoulliNB                          3.19  \n",
      "LinearDiscriminantAnalysis         103.23  \n",
      "SGDClassifier                       10.68  \n",
      "SVC                                177.55  \n",
      "KNeighborsClassifier                 4.72  \n",
      "QuadraticDiscriminantAnalysis       48.85  \n",
      "LabelSpreading                       9.42  \n",
      "LabelPropagation                     9.81  \n",
      "CalibratedClassifierCV            1005.34  \n",
      "DummyClassifier                      3.55  \n"
     ]
    }
   ],
   "source": [
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e58e728",
   "metadata": {},
   "source": [
    "### Saving predictions for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0372ca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe for submission\n",
    "submission = pd.DataFrame({'tweet_id': X_test_vect['tweet_id'], 'label': test_predictions})\n",
    "\n",
    "# Save the submission dataframe to a txt file\n",
    "submission.to_csv('C:\\\\Users\\\\danij\\\\Documents\\\\UC3M\\\\TFG\\\\PREDICTIONS\\\\answer.txt', mode='w', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
