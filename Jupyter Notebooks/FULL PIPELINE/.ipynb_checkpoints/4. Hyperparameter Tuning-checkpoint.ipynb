{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea3264b4",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd908946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ec3736",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de5ab676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>therapy</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>sia_positive_word_rate</th>\n",
       "      <th>sia_negative_word_rate</th>\n",
       "      <th>neutral_score</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>body_len</th>\n",
       "      <th>compound_score</th>\n",
       "      <th>punct%</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>neutral_score.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1454224517895688192</td>\n",
       "      <td>adderall</td>\n",
       "      <td>neutral</td>\n",
       "      <td>wait get adderall prescription imma time every...</td>\n",
       "      <td>4.692308</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>29</td>\n",
       "      <td>61</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1426258820376842243</td>\n",
       "      <td>oxycodone</td>\n",
       "      <td>negative</td>\n",
       "      <td>sassychickie kellyrdc fentanyl oxycontin oxyco...</td>\n",
       "      <td>6.846154</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>30</td>\n",
       "      <td>89</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1473007602170798082</td>\n",
       "      <td>cbd</td>\n",
       "      <td>neutral</td>\n",
       "      <td>fun juggling act mine taking adderall drinking...</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571</td>\n",
       "      <td>43</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1561156143405502466</td>\n",
       "      <td>percocet</td>\n",
       "      <td>neutral</td>\n",
       "      <td>percocet roxycodone xanax crushed dust elevate...</td>\n",
       "      <td>4.160000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.781</td>\n",
       "      <td>57</td>\n",
       "      <td>105</td>\n",
       "      <td>-0.4215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1559923718578741248</td>\n",
       "      <td>adderall</td>\n",
       "      <td>negative</td>\n",
       "      <td>first day adderall feel</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>14</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id    therapy     label  \\\n",
       "0  1454224517895688192   adderall   neutral   \n",
       "1  1426258820376842243  oxycodone  negative   \n",
       "2  1473007602170798082        cbd   neutral   \n",
       "3  1561156143405502466   percocet   neutral   \n",
       "4  1559923718578741248   adderall  negative   \n",
       "\n",
       "                                        cleaned_text  avg_word_length  \\\n",
       "0  wait get adderall prescription imma time every...         4.692308   \n",
       "1  sassychickie kellyrdc fentanyl oxycontin oxyco...         6.846154   \n",
       "2  fun juggling act mine taking adderall drinking...         4.545455   \n",
       "3  percocet roxycodone xanax crushed dust elevate...         4.160000   \n",
       "4                           first day adderall feel          4.750000   \n",
       "\n",
       "   sia_positive_word_rate  sia_negative_word_rate  neutral_score  \\\n",
       "0                0.153846                     0.0          1.000   \n",
       "1                0.230769                     0.0          1.000   \n",
       "2                0.136364                     0.0          0.571   \n",
       "3                0.080000                     0.0          0.781   \n",
       "4                0.375000                     0.0          1.000   \n",
       "\n",
       "   stopword_count  body_len  compound_score  punct%  positive_score  \\\n",
       "0              29        61          0.0000     1.6           0.000   \n",
       "1              30        89          0.0000    10.1           0.000   \n",
       "2              43       100          0.6249     1.0           0.331   \n",
       "3              57       105         -0.4215     0.0           0.000   \n",
       "4              14        38          0.0000     0.0           0.000   \n",
       "\n",
       "   negative_score  neutral_score.1  \n",
       "0           0.000            1.000  \n",
       "1           0.000            1.000  \n",
       "2           0.097            0.571  \n",
       "3           0.219            0.781  \n",
       "4           0.000            1.000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\danij\\\\Documents\\\\UC3M\\\\TFG\\\\DATA\\\\data_cleaned_features.csv\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c7e81f",
   "metadata": {},
   "source": [
    "### Convert label to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92a51f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>therapy</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>sia_positive_word_rate</th>\n",
       "      <th>sia_negative_word_rate</th>\n",
       "      <th>neutral_score</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>body_len</th>\n",
       "      <th>compound_score</th>\n",
       "      <th>punct%</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>neutral_score.1</th>\n",
       "      <th>num_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1454224517895688192</td>\n",
       "      <td>adderall</td>\n",
       "      <td>neutral</td>\n",
       "      <td>wait get adderall prescription imma time every...</td>\n",
       "      <td>4.692308</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>29</td>\n",
       "      <td>61</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1426258820376842243</td>\n",
       "      <td>oxycodone</td>\n",
       "      <td>negative</td>\n",
       "      <td>sassychickie kellyrdc fentanyl oxycontin oxyco...</td>\n",
       "      <td>6.846154</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>30</td>\n",
       "      <td>89</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1473007602170798082</td>\n",
       "      <td>cbd</td>\n",
       "      <td>neutral</td>\n",
       "      <td>fun juggling act mine taking adderall drinking...</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571</td>\n",
       "      <td>43</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1561156143405502466</td>\n",
       "      <td>percocet</td>\n",
       "      <td>neutral</td>\n",
       "      <td>percocet roxycodone xanax crushed dust elevate...</td>\n",
       "      <td>4.160000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.781</td>\n",
       "      <td>57</td>\n",
       "      <td>105</td>\n",
       "      <td>-0.4215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1559923718578741248</td>\n",
       "      <td>adderall</td>\n",
       "      <td>negative</td>\n",
       "      <td>first day adderall feel</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>14</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id    therapy     label  \\\n",
       "0  1454224517895688192   adderall   neutral   \n",
       "1  1426258820376842243  oxycodone  negative   \n",
       "2  1473007602170798082        cbd   neutral   \n",
       "3  1561156143405502466   percocet   neutral   \n",
       "4  1559923718578741248   adderall  negative   \n",
       "\n",
       "                                        cleaned_text  avg_word_length  \\\n",
       "0  wait get adderall prescription imma time every...         4.692308   \n",
       "1  sassychickie kellyrdc fentanyl oxycontin oxyco...         6.846154   \n",
       "2  fun juggling act mine taking adderall drinking...         4.545455   \n",
       "3  percocet roxycodone xanax crushed dust elevate...         4.160000   \n",
       "4                           first day adderall feel          4.750000   \n",
       "\n",
       "   sia_positive_word_rate  sia_negative_word_rate  neutral_score  \\\n",
       "0                0.153846                     0.0          1.000   \n",
       "1                0.230769                     0.0          1.000   \n",
       "2                0.136364                     0.0          0.571   \n",
       "3                0.080000                     0.0          0.781   \n",
       "4                0.375000                     0.0          1.000   \n",
       "\n",
       "   stopword_count  body_len  compound_score  punct%  positive_score  \\\n",
       "0              29        61          0.0000     1.6           0.000   \n",
       "1              30        89          0.0000    10.1           0.000   \n",
       "2              43       100          0.6249     1.0           0.331   \n",
       "3              57       105         -0.4215     0.0           0.000   \n",
       "4              14        38          0.0000     0.0           0.000   \n",
       "\n",
       "   negative_score  neutral_score.1  num_label  \n",
       "0           0.000            1.000          0  \n",
       "1           0.000            1.000          2  \n",
       "2           0.097            0.571          0  \n",
       "3           0.219            0.781          0  \n",
       "4           0.000            1.000          2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_label = {'neutral': 0, 'positive': 1, 'negative': 2}\n",
    "\n",
    "data['num_label'] = data['label'].map(sentiment_label)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059989a5",
   "metadata": {},
   "source": [
    "### Split into train, validation, and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74906a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide variables into features and labels\n",
    "\n",
    "# Keep only numeric features\n",
    "features = data[['tweet_id', 'num_label', \n",
    "     'avg_word_length', 'sia_positive_word_rate', 'sia_negative_word_rate', 'neutral_score', 'stopword_count', \n",
    "     'body_len', 'compound_score', 'punct%', 'positive_score', 'negative_score', 'neutral_score']]\n",
    "\n",
    "labels = data['num_label']\n",
    "\n",
    "# First split into train(60%) and test(40%), as we can only split dataset into 2\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.4, random_state=42)\n",
    "\n",
    "# Now split test(40%) into test(20%) and validation(20%)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45496317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1805\n",
      "1805\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c109f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "0.2\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "# Check if we splitted correctly\n",
    "for dataset in [y_train, y_val, y_test]:\n",
    "    print(round(len(dataset) / len(labels), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd671df",
   "metadata": {},
   "source": [
    "### Perform GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5dd20235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to show performance of hyperparameters\n",
    "def print_results(results):\n",
    "    # Print the best parameters found during the cross-validation\n",
    "    print('BEST PARAMS: {}\\n'.format(results.best_params_))\n",
    "\n",
    "    # Extract the mean and standard deviation of the test scores from the results object\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "\n",
    "    # Iterate over the means, stds, and params simultaneously using the zip function\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        # Print the mean score, the range (mean +/- 2 * std), and the corresponding parameters\n",
    "        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1640bbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'max_depth': 10, 'n_estimators': 100}\n",
      "\n",
      "0.837 (+/-0.192) for {'max_depth': 2, 'n_estimators': 5}\n",
      "0.781 (+/-0.083) for {'max_depth': 2, 'n_estimators': 50}\n",
      "0.801 (+/-0.092) for {'max_depth': 2, 'n_estimators': 100}\n",
      "0.807 (+/-0.079) for {'max_depth': 2, 'n_estimators': 200}\n",
      "0.975 (+/-0.036) for {'max_depth': 10, 'n_estimators': 5}\n",
      "0.999 (+/-0.002) for {'max_depth': 10, 'n_estimators': 50}\n",
      "1.0 (+/-0.0) for {'max_depth': 10, 'n_estimators': 100}\n",
      "1.0 (+/-0.0) for {'max_depth': 10, 'n_estimators': 200}\n",
      "0.977 (+/-0.022) for {'max_depth': 20, 'n_estimators': 5}\n",
      "1.0 (+/-0.0) for {'max_depth': 20, 'n_estimators': 50}\n",
      "1.0 (+/-0.0) for {'max_depth': 20, 'n_estimators': 100}\n",
      "1.0 (+/-0.0) for {'max_depth': 20, 'n_estimators': 200}\n",
      "0.988 (+/-0.02) for {'max_depth': None, 'n_estimators': 5}\n",
      "1.0 (+/-0.0) for {'max_depth': None, 'n_estimators': 50}\n",
      "1.0 (+/-0.0) for {'max_depth': None, 'n_estimators': 100}\n",
      "1.0 (+/-0.0) for {'max_depth': None, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Try different models and see their performance\n",
    "\n",
    "# Create an instance of the Random Forest Classifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Define the parameters to be tuned in the grid search\n",
    "parameters = {\n",
    "    'n_estimators': [5, 50, 100, 200],\n",
    "    'max_depth': [2, 10, 20, None]\n",
    "}\n",
    "\n",
    "# Create an instance of GridSearchCV with the Random Forest Classifier and parameter grid\n",
    "cv = GridSearchCV(rf, parameters, cv=5)\n",
    "\n",
    "# Fit the training features and labels to the grid search cross-validation\n",
    "cv.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Print the results of the grid search cross-validation\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49b65dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_estimator_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
